# hierarchical structure of tourist spot dataset-master

## 필요 사항

* beautifulsoup, selenium 라이브러리의 설치가 필요합니다

* instagram_crawler.ipnb 파일과 같은 디렉토리에 
chromedriver.exe 파일이 있어야 합니다.

## 사용법

### Instagram_crawler.py
검색할 태그의 이름과 스크롤할 수, 스크롤을 시작할 페이지 수를 입력하면 데이터를 크롤링 할 수 있습니다.

	** 원하는 태그를 입력하세요: 
	>>> 경복궁

	** 스크롤 할 페이지 수를 입력하세요.
	 한 번의 스크롤 마다 약 35~40개의 데이터가 획득됩니다: 
	>>> 20

	** 스크롤을 시작할 페이지 번호를 입력하세요.
	 맨 처음 데이터부터 가져오고 싶다면 1을 입력하세요:
	 >>> 1

이미지 파일은 .jpg의 형태로 저장되며
사용자 아이디, 좋아요 수, 텍스트, 해시태그, 레이블은 json의 형태로 저장됩니다.

### Preprocess_data.py
수집된 이미지 파일의 폴더와 .json파일의 경로를 입력하여 데이터의 전처리를 진행할 수 있습니다.

	** 전처리를 진행할 .json 파일의 경로를 입력하세요:
	>>> ./dataset/label_경복궁.json
	경로를 저장하였습니다.

	** 전처리를 진행할 이미지 폴더의 경로를 입력하세요:
	>>>./dataset/img/경복궁
	경로를 저장하였습니다.

	중복 데이터 삭제를 시작합니다
	
입력하면 바로 중복 데이터의 검사가 시작됩니다. 검사가 끝나면 중복 데이터의 목록을 출력하며, 사용자는 이를 확인한 후 삭제 여부를 결정할 수 있습니다.
중복 데이터의 삭제 이후, 삭제할 이미지의 이름을 입력하여 이미지 파일과 .json 파일 내의 데이터를 동시에 제거할 수 있습니다.

숫자가 아닌 아무키나 입력하면 프로그램을 종료할 수 있습니다.
이때, 삭제된 데이터는 휴지통으로 들어가지 않고 바로 삭제되어 복구가 어려우니 주의하시기 바랍니다.
또한 형식에 맞지않는 .json파일의 경우, 파일 로딩중 에러가 발생하여 데이터가 삭제될 위험이 있으니 주의하시기 바랍니다.
	
	사용자가 선택한 데이터의 삭제를 시작합니다.
	삭제할 데이터의 이미지 번호를 입력하고 엔터를 치세요.

	프로그램을 끝내려면 숫자가 아닌 아무 키나 입력하세요.

	!!!주의!!!
	삭제된 이미지 데이터는 휴지통으로 들어가지 않습니다. (=복구하기 어렵습니다.)


	>>> 4
	4  삭제 완료

	>>> 10
	10  삭제 완료

	>>> q
	프로그램을 종료합니다.
